{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import cv2\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "### Global Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d157dc1311928d1ada13ed2ef4a34c4ea5c0b538"
   },
   "outputs": [],
   "source": [
    "\n",
    "NUM_CLASSES = 164\n",
    "\n",
    "\n",
    "CHANNELS = 3\n",
    "\n",
    "IMAGE_RESIZE = 64\n",
    "RESNET50_POOLING_AVERAGE = 'max'  #max\n",
    "DENSE_LAYER_ACTIVATION = 'softmax'  #sigmoid\n",
    "OBJECTIVE_FUNCTION = 'categorical_crossentropy'  \n",
    "\n",
    "# Common accuracy metric for all outputs, but can use different metrics for different output\n",
    "LOSS_METRICS = ['accuracy']\n",
    "\n",
    "# EARLY_STOP_PATIENCE must be < NUM_EPOCHS\n",
    "NUM_EPOCHS = 20\n",
    "EARLY_STOP_PATIENCE = 3\n",
    "\n",
    "# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n",
    "# Training images processed in each step would be no.-of-train-images / STEPS_PER_EPOCH_TRAINING\n",
    "STEPS_PER_EPOCH_TRAINING = 500  #500\n",
    "STEPS_PER_EPOCH_VALIDATION = 500\n",
    "\n",
    "# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n",
    "# NOTE that these BATCH* are for Keras ImageDataGenerator batching to fill epoch step input\n",
    "BATCH_SIZE_TRAINING = 64\n",
    "BATCH_SIZE_VALIDATION = 64\n",
    "\n",
    "# Using 1 to easily manage mapping between test_generator & prediction for submission preparation\n",
    "BATCH_SIZE_TESTING = 64  #32(half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ee0da10690e2848537102cb0c74f9fe19a50431b"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.applications import ResNet50\n",
    "from tensorflow.python.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.layers import Conv2D\n",
    "from tensorflow.python.keras.layers import MaxPooling2D\n",
    "from tensorflow.python.keras.layers import Flatten\n",
    "from tensorflow.python.keras.layers import Dropout\n",
    "### \n",
    "### Below systax is available with TensorFlow 1.11 onwards but this upgrade is not available for Kaggle kernel yet\n",
    "###\n",
    "#import tensorflow as tf\n",
    "#print(tf.__version__)\n",
    "#import tensorflow as tf\n",
    "#from tf.keras.applications import ResNet50\n",
    "#from tf.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b651539464d36c7443a601e914479f0d2153f435"
   },
   "source": [
    "### ResNet50\n",
    "\n",
    "* The xyz_tf_kernels.h5 weights is useful for pure prediction of test image and this prediction will rely completely on ResNet50 pre-trained weights, i.e., it does not expected any training from our side\n",
    "* Out intention in this kernel is Transfer Learning by using ResNet50 pre-trained weights except its TOP layer, i.e., the xyz_tf_kernels_NOTOP.h5 weights... Use this weights as initial weight for training new layer using train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2fc47c3f887e6713b5a2be38c02b38a8ec80bf97"
   },
   "outputs": [],
   "source": [
    "resnet_weights_path = '../input/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "#Still not talking about our train/test data or any pre-processing.\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#1st layer as the lumpsum weights from resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
    "#NOTE that this layer will be set below as NOT TRAINABLE, i.e., use it as is\n",
    "model.add(VGG19(include_top = False, pooling = RESNET50_POOLING_AVERAGE, weights = resnet_weights_path, input_shape = (64,64,3)))\n",
    "\n",
    "#model.add(AvgPooling2D(pool)) model.summary()\n",
    "model.add(Dense(2048 , activation = 'tanh'))\n",
    "model.add(Dense(1024 , activation = 'tanh'))\n",
    "model.add(Dense(1024 , activation = 'tanh'))\n",
    "model.add(Dense(512 , activation = 'tanh'))\n",
    "model.add(Dense(512, activation = 'tanh'))\n",
    "model.add(Dense(256, activation = 'tanh'))\n",
    "model.add(Dense(256, activation= 'tanh'))\n",
    "model.add(Dense(128, activation= 'tanh'))\n",
    "#model.add(Dense(64, activation= 'tanh'))\n",
    "#model.add(Dense(32, activation= 'tanh'))\n",
    "\n",
    "model.add(Dense(NUM_CLASSES, activation = DENSE_LAYER_ACTIVATION))\n",
    "\n",
    "#Say not to train first layer (ResNet) model as it is already trained\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b617a28f0f89b272a0aa2af6cf72f2dd642ee052"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3587981a5b6b1d6ff8221738d51d78cafb2dd02c"
   },
   "source": [
    "### Compile Our Transfer Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "670238611770f43a056332cc06efff44e20ad124"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import optimizers\n",
    "\n",
    "sgd = optimizers.SGD(lr = 0.01, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "model.compile(optimizer = sgd, loss = OBJECTIVE_FUNCTION, metrics = LOSS_METRICS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8d003a99fe4ff58b8905c7f6b5286d97a852cb7a"
   },
   "source": [
    "### Prepare Keras Data Generators\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ac9ebd909fee81c8c8d9b9fccb6590944d8106eb"
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "image_size = IMAGE_RESIZE\n",
    "\n",
    "# preprocessing_function is applied on each image but only after re-sizing & augmentation (resize => augment => pre-process)\n",
    "# Each of the keras.application.resnet* preprocess_input MOSTLY mean BATCH NORMALIZATION (applied on each batch) stabilize the inputs to nonlinear activation functions\n",
    "# Batch Normalization helps in faster convergence\n",
    "data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# flow_From_directory generates batches of augmented data (where augmentation can be color conversion, etc)\n",
    "# Both train & valid folders must have NUM_CLASSES sub-folders\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "        '../input/ear-dataset/dataset2/train',\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=BATCH_SIZE_TRAINING,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "        '../input/ear-dataset/dataset2/test',\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=BATCH_SIZE_VALIDATION,\n",
    "        class_mode='categorical') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5014f91b6aeae661f0bc5db5d546089a07ca5b9d"
   },
   "outputs": [],
   "source": [
    "# Max number of steps that these generator will have opportunity to process their source content\n",
    "# len(train_generator) should be 'no. of available train images / BATCH_SIZE_TRAINING'\n",
    "# len(valid_generator) should be 'no. of available train images / BATCH_SIZE_VALIDATION'\n",
    "(BATCH_SIZE_TRAINING, len(train_generator), BATCH_SIZE_VALIDATION, len(validation_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2dfad78129d725f42110cde0270c32d7373d6d1d"
   },
   "outputs": [],
   "source": [
    "# Early stopping & checkpointing the best model in ../working dir & restoring that as our model for prediction\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "cb_early_stopper = EarlyStopping(monitor = 'val_accuracy', patience = EARLY_STOP_PATIENCE)\n",
    "cb_checkpointer = ModelCheckpoint(filepath = '../working/best.hdf5', monitor = 'val_accuracy', save_best_only = True, mode = 'auto')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cf85fe3c0653aa56503b7da058ea8acf445eec6e"
   },
   "outputs": [],
   "source": [
    "fit_history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=STEPS_PER_EPOCH_TRAINING,\n",
    "        epochs = NUM_EPOCHS,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=STEPS_PER_EPOCH_VALIDATION,\n",
    "        callbacks=[cb_checkpointer, cb_early_stopper]\n",
    ")\n",
    "model.load_weights(\"../working/best.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1ef4dd95f6d12f9277255576645e8bfce5270b81"
   },
   "source": [
    "### Training Metrics\n",
    "\n",
    "One of the default callbacks that is registered when training all deep learning models is the History callback. It records training metrics (training accuracy, training loss, validation loss & validation accuracy) for each epoch. Note that training accuracy & loss during epoch steps are somewhat incomplete information and they are not recorded in history.\n",
    "\n",
    "Observe that training uses early stopping, hence metrics is available for epochs run, not for NUM_EPOCHS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "383d7a0aa87e1508a46fcebfcd5a80d7aafb840f"
   },
   "outputs": [],
   "source": [
    "print(fit_history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "00e51568f7e6022c6738c0e1a41080bc7152c257"
   },
   "outputs": [],
   "source": [
    " plt.figure(1, figsize = (15,8)) \n",
    "    \n",
    "    \n",
    "plt.subplot(221)  \n",
    "plt.plot(fit_history.history['acc'])  \n",
    "plt.plot(fit_history.history['val_acc'])  \n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('accuracy')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'valid']) \n",
    "    \n",
    "plt.subplot(222)  \n",
    "plt.plot(fit_history.history['loss'])  \n",
    "plt.plot(fit_history.history['val_loss'])  \n",
    "plt.title('model loss')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'valid']) \n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
